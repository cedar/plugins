# Welcome to the cedar plugin collection #

This is a collection of plugins for [cedar](http://cedar.ini.rub.de).

# Building the plugin #

TODO describe how to build the plugin

# Using shared buildsets #

To use one of the shared buildsets follow these steps:

1. Enter your build directory. Remove your CMakeCache.txt if it exists.
2. In the build directory, type ```cmake -D BUILDSET=shared_buildsets/TheBuildsetYouWantToUse.cmake ..```
3. Type ```make all``

Note that the name of the library generated by differnt buildsets differs. Make sure to use the appropriate shared object!

# Plugin configurations #

TODO find a better name for plugin configurations

Each pulgin configuration defines two things: 1. the name of the plugin being built; and, 2. what classes to build into
the plugin. To declare a plugin configuration, create a buildset (put it into the shared_buildsets folder if you want
others to have access to it) or edit the buildset.cmake in the root directory.

First, declare the name of the plugin configuration using

    DECLARE_PLUGIN(MyPlugin)

This tells the buildsystem that the shared object (or dll on Windows, dylib on Mac OS) should be named
libMyPlugin.so (Windows: MyPlugin.dll, Mac OS: libMyPlugin.dylib).

Next, you should add classes to this plugin. This is done with the `ADD_TO_PLUGIN` command, which offers various
options. To add a specific step class, call it like this:

    ADD_TO_PLUGIN(STEP some::Step)

You can also add multiple steps:

    ADD_TO_PLUGIN(STEPS some::Step some::other::Step)

If you want to add all steps from a category, you can write

    ADD_TO_PLUGIN(CATEGORY YourCategory)
    
As before, you can add multiple categories like this:

    ADD_TO_PLUGIN(CATEGORIES YourCategory YourOtherCategory)
    
Note that you can combine several of these commands in a single `ADD_TO_PLUGIN` call, for example:

    ADD_TO_PLUGIN(STEPS some::Step some::other::Step CATEGORY YourCategory)
    
Finally, you can add all classes of a kind using these commands:

    ADD_TO_PLUGIN(ALL_STEPS ALL_KERNELS)


# Steps included in the plugin #

| step                         | description                                                                    |
|------------------------------|--------------------------------------------------------------------------------|
| **Dynamics**                                                                                                  |
| *InhibitoryNeuron*           | A single neuron with the dynamics tau * dv/dt = -sigmoid(s) * tanh(beta * (v - s)) - (1 - sigmoid(s)) * v, where v is the state of the system, beta defines the slope of change and s is the input, projected to zero dimensions by summing. |
| *SerialOrderRecruiting*      | An Extension of the Serial Order Step, that allows a dynamic growth of serial order nodes and optionally a recruition of additional Groups toghether with the RecruitGroupsScript. |
| *PatternMemory*              | A dynamics that relaxes to the input pattern as long as a learning input is active. |
| **Image Processing**                                                                                          |
| *GeometricImageTransform*    | Rescales and rotates and image around its center and then offsets it using geometric transformations. |
| *SteerC2C3*                  | Calculates the C2 and C3 component from steering filter responses.             |
| *SteerableFilter*            | Applies a steerable filter to an input.                                        |
| *SteeringAngle*              | Calculates the steering angle from C2/C3 responses.                            |
| *SteeringEnergy*             | Calculates the steering energy from C2/C3 responses.                           |
| **Keypoints**                                                                                                 |
| *DoubleStoppedCellResponses* | Extracts the double-stopped cell responses from keypoint data.                 |
| *KeypointExtractor*          | A step that extracts keypoint information.                                     |
| *KeypointLambdaMapping*      | A step that maps keypoint lambdas to other coordinate systems and vice versa.  |
| *KeypointLinesAndEdges*      | Extracts line- and edge information from a KeypointData object.                |
| *KeypointPatchRescaler*      | Rescales a local image patch according to a chosen keypoint size.              |
| *KeypointVisualization*      | Draws visualizations for a list of opencv keypoints onto an image.             |
| **Motion detection**                                                                                          |
| *CounterChangeCombination*   | The inputs have to be 3D toward and away matrices from a single edge filtered video or camera input. The first dimension of the input matrices is considered as the edge orientation dimension. The input matrices are shifted orthogonal the edge orientation by the size of the configurable shift parameter. Output matrices are two 3D matrices that reflect the combination of toward and away signals according to the counter-change rule. The first dimension is assigned to the motion direction. The two matrices represent the polarity if a dark pattern moves on bright ground (BtW: Black to White motion) or the other way around (WtB: White to Black motion) |
| *MotionGradient*             | This class provides a cedar processing step implementing the OpenCV function calcMotionGradient. |
| **Nao**                                                                                                       |
| *NaoCamera*                  | Nao's camera.                                                                  |
| **Object Recognition**                                                                                        |
| *FeatureStacks*              | This step builds localized histograms around keypoints. See Lomp et al. (2014) for details. |
| *KeypointEdgeHistogramExtractor* | This step builds localized histograms around keypoints using shape features.   |
| *ReceptiveFieldHistogram*    | Extracts histograms using localized receptive fields.                          |
| *TopDownReconstruction*      | Reconstructs a shape based object representation.                              |
| *ViewCombination*            | Subsamples discrete activation fields by summing up neighboring sampling points (1D only). This is intended for object recognition, where multiple nodes representing multiple object views may be summed to form a representation of a single object. |
| **Sources**                                                                                                   |
| *ImageProvider*              | A step that outputs an image from a directory based on an index specified via a parameter. |
| *KinectReader*               | A source that reads a Kinect camera, yielding images and depth images, as well as a RGBA point cloud. |
| *SpatialPattern*             | Outputs a matrix of synaptic weights that correspond to a spatial relational template (e.g., "to the left of"). |
| **Utilities**                                                                                                 |
| *AttentionSlice*             | A step that determines the location of the maximum in an activation matrix and cuts out a region around this location from an input image. |
| *BufferThief*                | This step can grab any buffer from a step in the same architecture and output the data in the buffer. Use with caution, as this may lead to issues due to unsafe/unlocked data. |
| *ConvertDepthToXyz*          | A step that converts depth data into 3D object data with scale and matrix center |
| *CrossCorrelation*           | Calculates the cross correlation in different configurations.                  |
| *Demultiplexer*              | Splits a vector (1xn or nx1 matrix) into individual scalars (1x1 matrices).    |
| *EgoToBirdView*              | A step that converts camera input and distance information to a top-down representation. |
| *ElementwiseDivide*          | To input matrices Nom and Denom will be divided elementwisely. The output is Nom/(Denom + scalar). "scalar" is a scalar and configurable parameter. This value is added to all elements in the Denom matrix to prevent dividing by zero or very small values. |
| *HarmonicOscillator*         | A looped step that employs the harmonic Oscillator Formula pdotdot = -K(p-x)-B*pdot. K and B are automatically set to the critically damped solution. |
| *HyperAcuteRescaling*        | Rescales an input matrix so that as little information as possible is lost. Note that this step's output is not properly normalized. |
| *Integrator*                 | A looped step that integrates nx1 inputs across time.                          |
| *LabelString*                | Outputs a label and ordered list of labels for activation from a label field.  |
| *LabelWMAnnotator*           | Takes a yarp-friendly label WM representation and puts labels into an image.   |
| *MatrixThreadDecoupler*      | A looped step that makes a copy of its input matrix. This may help make threads more independent of each other. |
| *MaxPooling*                 | Subsamples a matrix by taking the maximum over rectangular regions.            |
| *Multiplexer*                | Joins several scalars (1x1 matrices) into a vector (nx1 matrix).               |
| *PadAndTranslate*            | A step that converts a 1D representation into a larger frame and translates the center of the 1D representation to the position given by the skalar-translation input. Borders are cyclic. |
| *PointWiseNormalization*     | Normalizes the entries along one dimension of a matrix.                        |
| *RewardHebbTrace*            | A step that learns an associated input in presence of a reward signal          |
| *ShiftedAddition*            | no description.                                                                |
| *TransformPointCloud*        | A step that performs geometric operations on a point cloud, yielding the transformed point cloud and camera position. |
| *WeightedSum*                | A looped step that multiplies each input value with a given weight and sums them up across each input dimension. The given weight function encodes the distance from the center of the input matrix. This step is used to calculate a velocity signal dependent on the distance between a peak position and the center of the input matrix. |
| *WeightedSumOfSlices*        | Calculates a weighted sum of the entries in a 3d or 4d matrix along the first dimension. |




# Group templates included in the plugin #

| group template               | description                                                                    |
|------------------------------|--------------------------------------------------------------------------------|
| *edge histogram rotation*    | Template forward rotating localized edge histograms within the CF thesis architecture. |
| *edge rotation estimation*   | Mathing of rotation based on localized edge histograms.                        |
| *histogram label matching*   | Mathing for labels based on localized histograms.                              |
| *histogram shift estimation* | Mathing of shift based on localized histograms.                                |
| *localized histogram extraction* | Template for extracting localized histograms within the CF thesis architecture. |
| *localized histogram forward shift* | Template forward shifting localized histograms within the CF thesis architecture. |
| *steering filter bank*       | Applies a bank of steering filters and calculates energy and angle for each pixel. |




# Kernels included in the plugin #

| kernel                       | description                                                                    |
|------------------------------|--------------------------------------------------------------------------------|
| *MotionKernel*               | This is a general version of the gauss kernel class. A global inhibition term can be added to each dimension separately. There is an amplitude parameter which scales the gaussian local excitation of each dimension but not the global inhibition term of this dimension. The benefit of this class in contrast to the usual Gauss kernel is that it is possible to introduce global excitation along only one dimension. This is, e.g., important for motion detection where you want to detect a single direction selective motion percept (global inhibition for motion direction) but for multiple objects (no global inhibition in the space dimension). |
| *SteerableKernel*            | A collection of steerable kernels that can be used to quickly calculate edge orientations and strengths. |




# Data structures included in the plugin #

| data structure               | description                                                                    |
|------------------------------|--------------------------------------------------------------------------------|
| *KeypointData*               | A data structure that holds a vislab::keypoints::KPData object.                |
| *KeypointListData*           | A std::vector of (open)cv::Keypoints.                                          |
| *RGBAPointCloudData*         | A data structure that holds Kinect point cloud data.                           |
| *StringData*                 | A data structure that holds a string.                                          |
| *AsyncGrabber*               | A data structure that holds refreshed Kinect image data.                       |




# Plots included in the plugin #

| plot                         | description                                                                    |
|------------------------------|--------------------------------------------------------------------------------|
| *StringPlot*                 | A plot that displays a string (cedar::aux::StringData).                        |




# External libraries used by the plugin #

## naoqi ##

TODO describe how to get, build and include the naoqi.
## vislab_toolbox ##

TODO describe how to get, build and include the vision lab toolbox.

